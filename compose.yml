version: "3.7"

services:
  # Compute Node
  compute:
    build: "./" # TODO: use image from registry
    env_file:
      - .env.compose
    environment:
      OLLAMA_HOST: "http://host.docker.internal"
      OLLAMA_PORT: "11434"
      RUST_LOG: "${DKN_LOG_LEVEL:-info}"
    restart: "on-failure"

  # Ollama Container (CPU)
  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - ~/.ollama:/root/.ollama
    profiles: [ollama-cpu]

  # Ollama Container (ROCM)
  ollama-rocm:
    image: ollama/ollama:rocm
    ports:
      - 11434:11434
    volumes:
      - ~/.ollama:/root/.ollama
    devices:
      - "/dev/kfd"
      - "/dev/dri"
    profiles: [ollama-rocm]

  # Ollama Container (CUDA)
  ollama-cuda:
    image: ollama/ollama
    ports:
      - 11434:11434
    volumes:
      - ~/.ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles: [ollama-cuda]

volumes:
  ollama:
